\chapter*{Préambule: Apprentissage humain, Apprentissage Machine et Généralisation}
\addcontentsline{toc}{chapter}{Préambule: Apprentissage Humain, Apprentissage Machine \\
et Généralisation}\mtcaddchapter

\addtextlist{lof}{Preamble}

Ce manuscrit étudie la question de la \emph{généralisation} des algorithmes d'apprentissage machine, notion construite autour de celle d'\emph{apprentissage} en apprentissage machine
Pour un bref instant, prenons le luxe d'oublier les machines pour se concentrer sur l'apprentissage en ce qu'il a de plus humain.

\paragraph{Appréhender l'apprentissage humain.}
Un humain, en premier lieu, va se structurer autour d'expériences, vécues ou transmises par autrui. L'être apprenant va alors tirer bénéfice de ces vécus via diverses modalités, par exemple, en considérant une expérience médiée comme vraie (le feu brûle) et agir en fonction de ce postulat alors que la réitération ou la négation de cette même information peuvent être des symptômes d'une valeur de vérité nulle.  Ces scénarios peuvent tout aussi bien apparaître pour une expérience vécue (hallucinations). Cette première dichotomie quant au traitement de l'information est intrinsèquement liée à une question clairement énoncée : est-ce que le feu brûle? Puis-je me fier à mes sens ou ai-je halluciné ? Dans ces cas de figure, l'apprentissage a eu lieu à travers l'assujettissement de l'expérience à sa valeur de vérité par rapport à une question simple (ici à deux issues).  Cette vision peut facilement s'étendre à une arborescence multiple (et finie) de possibles. En effet, on peut étendre la question de la brûlure comme suit: quelle est l'intensité de la brûlure en fonction de la température du feu? On peut dès lors établir une multitude de réponses représentant divers degrés de brûlure.
  
 Néanmoins, de nombreuses questions ne peuvent se réduire à un nombre fini de possibilités. Par exemple, qu'est-ce que le feu? Pour répondre à cette question, il est néanmoins possible d'exploiter de multiples facettes d'expériences (feu de bois, brindille, roche) pour proposer le feu comme étant la réaction chimique de l'oxygène de l'air avec un matériau combustible, un apport d'énergie servant de déclencheur. 

Il est alors légitime de se demander pourquoi l'apprenant a eu besoin de comprendre la vraie nature du feu. Cette  compréhension fondamentale des choses émerge de considérations pratiques : comment ne plus avoir froid? Peut-on manger de la viande autrement que crue pour diminuer les risques de maladie? Il faut alors de multiples interactions avec l'environnement pour générer des expériences et ensuite apprendre d'elles pour répondre graduellement à un besoin complexe (comment faire un feu pour se réchauffer?).
    
Ainsi, par cette analyse préliminaire, nous avons trouvé plusieurs prémices de compréhension de l'apprentissage chez l'homme.
    \begin{itemize}
        \item Comment l'apprentissage se formalise-t-il structurellement ?
        L'apprenant doit abâtardir l'expérience à des questions simples pour acquérir des certitudes primaires. Ces dernières acquises, il est possible d'atteindre des questions complexes en imbriquant de plus en plus de considérations élémentaires. 
        \item D'où provient le besoin d'apprendre ? D'un point de vue pratique, l'émergence de ces questions complexes dérive bien souvent d'un rapport de l'être à son environnement, permettant d'élaborer des objectifs contextuels. L'apprenant devient alors graduellement capable de répondre à des besoins complexes par une succession d'actions simples.
    \end{itemize}

\paragraph{De l'apprentissage humain à l'apprentissage machine.}
    L'apprentissage machine s'est structuré autour de deux approches, une première symbolique qui tire profit des extrapolations humaines pour apprendre à la machine à manipuler une axiomatique et une seconde, statistique, qui consiste à fournir bon nombre d'expériences à la machine pour lui faire apprendre par de multiples exemples empiriques. Nous allons nous focaliser sur la seconde approche car, elle sous-tend une large partie de la recherche moderne.
    Cette méthode requiert de nombreuses expériences transmises à la machine qui en extrait les connaissances à travers des procédures optimisatoire. Plus précisément, la connaissance extraite dépend de la question posée ainsi que sa traduction mathématique. Nous pouvons alors relever des parallèles avec l'apprentissage humain décrit plus haut: il faut des expériences et une question pour réduire le réel à quelque chose d'apprenable. Pour aller plus loin, la variétés des scenarii d'apprentissages humain décrits au dessus ont une correspondance dans l'apprentssage machine moderne: à la question "Le feu brûle-t-il?" on peut associer l'apprentissage supervisé qui traite apprend sur des questions à choix multiples. A la question "qu'est-ce que le feu?", on peut associer l'apprentissage non-supervisé qui va chercher, dans le cas du clustering (ou regroupement), des similitudes non-induites par la question entre diverses expériences. Finalement, quant à l'interaction avec l'environnement et la question "puis-je faire un feu?", elle est associée à l'apprentissage par renforcement qui étudie l'apprentissage d'un agent qui interagit avec son environnement. 
    
\paragraph{Comprendre la généralisation depuis l'apprentissage.}
 La généralisation peut être vue comme la capacité d'exploiter l'apprentissage d'une expérience au delà de cette dernière. Cela englobe une compréhension théorique et axiomatique d'un phénomène, i.e. une extrapolation fructueuse ou bien la capacité à exploiter la connaissance acquise pour une situation inédite, jamais vue auparavant, \ie interpoler des expériences. 
    
     Ce double aspect de la généralisation se retrouve aussi bien chez l'homme que la machine sous diverses modalités. Les réseaux de neurones profonds, qui sont le fer de lance de l'apprentissage machine moderne, se basent sur des espaces de dimension finie pour apprendre, ce qui revient à dire qu'un problème peut être appris à travers un nombre fini de principes fondateurs. Le nombre de principes pouvant être augmentés autant que les capacités numériques le permettent, nous dirons alors que les réseaux de neurones ont une puissance discrète de généralisation. Etant donné que les méthodes d'apprentissage machine sont corrêlées à leur pendantes humaines, on peut alors se demander si la puissance de généralisation (et même d'apprentissage) humaine est également discrète. Il semble cavalier d'affirmer ceci car même s'il est possible de supposer que la part consciente de l'esprit humain raisonne à horizon finie et a une puissance dénombrable (transmise d'ailleurs à la machine, apprenant selon des modalités humaines), cette dimension occulte la quantité d'information  sans cesse captée et filtrée par notre cerveau ainsi que son assimilation inconsciente, relevant autant de la pensée abstraite que du biologique peut potentiellement générer une puissance de généralisation relevant d'un infini plus large et ainsi fournir une puissance de généralisation continue (relevant davantage de la ligne que du point). Dès lors, comment penser la généralisation chez l'homme alors que, mathématiquement, nos intuitions les plus simples nous font défaut lorsque cette puissance continue intervient (la boule de rayon 1 n'est pas compacte en dimension infinie, \citealp{riesz1955lecons})? On peut également se demander si l'extrapolation existe dans de telles structures ou si tout revient à interpoler \citep{hasson2020direct}.
    
\paragraph{Quid de la généralisation en apprentissage machine de nos jours?}
     Qu'espérer alors des réseaux de neurones artificiels et de leur capacité de généralisation relativement à l'humain? Les théorèmes d'approximations universels (voir \eg \citealp{lu2017expressive,park2021minimum}) assurent que les réseaux de neurones sont capables d'approximer n'importe quelle fonction vivant dans un espace à la puissance du continu (\eg l'espace des fonctions continues à support compact qui n'admet pas de base dénombrable en tant qu'espace de Banach), faisant de ces structures des candidats prometteurs pour appréhender partiellement les mécanismes humains de généralisation.
    Les approximations prodiguées par ces machines seront, dans un avenir proche, potentiellement suffisamment puissantes pour donner l'illusion d'une capacité de généralisation humaine. Néanmoins, il demeure bon de garder en tête que, si la thèse d'une inégalité fondamentale de nature entre les puissances de généralisation humaine et machine est avérée, alors les réseaux de neurones artificiels n'atteindront jamais pleinement les capacités de compréhension du monde de leurs homologues bilogiques. Reste que leur capacité à approximer cette intelligence toute humaine font de ces structures des assistants de valeur, enrichissant les capacités de tout individu.  Mieux comprendre la puissance de généralisation machine, être capable de la quantifier, d'identifier les mécanismes qui la favorisent sont les objets de ce manuscrit.  

    
    
    
    \begin{comment}
    TODO: parler des facettes humaines de généralisation: abstraire pour atteindre des principes généraux: oui mais ne pas perdre de vue les cas particuliers. --> Liens interpolations et extrapolation
    
    Parallèle: dvpt de la compréhension humaine consciente: espace de dimension finie dont la dimension ne cesse de croitre par l'apprentissage: similaire aux deep nets
    A contrario: mécaniques de la compréhension humaine, consciente ou inconsciente -> espace de dimension infinie
    
    DONC: on pourra de mieux en mieux comprendre et singer la compréhension humaine via des espaces de dimension finie car c tout ce que notre compréhension consciente permet, néanmoins cette compréhension aura toujours cette limite dénombrable, qui sera peut etre plus tard juste invisible (exemple actuel: chatGPT: 1kg de plomb aussi lourd que deux kilos de plumes)
    
    Plan : apprentissage humain done
    faire intervenir l'apprentissage machine en soulignant les correspondances entre les questions ci-dessus sur le feu et l'apprentissage supervisé, non-supervisé et par renforcement.
    
    Une fois les ppes généraux d'apprentissage discutés et corrêlés, parler de la généralisation: qu'est-ce qu'elle est pour l'homme? Interpolation et extrapolation chez l'homme puis parler des performances modernes des deep nets qui ont l'air également d'interpoler, extrapoler et overall véhiculer une forme de connaissance par la généralisation. Préciser néanmoins que pr une machine, interpolation et extrapolation se pensent ds un espace de dimension finie alors que l'apprentissage humain se base autant sur un esprit conscient dont on peut raisonnablement supposer qu'il apprend et généralise en modélisant le réel par un nombre fini de principes fondateurs qui ne cesse de croitre --> infini dénombrable mais l'apprentissage c'est aussi toutes ses données inconscientes qui pourraient placer l'apprentissage ds un espace de dimension infinie. Dès lors, comment penser la généralisation chez l'homme alors que nos intuitions les plus simples nous font défaut (la boule de rayon 1 n'est pas compacte en dim infinie, Heine), existe-t-il autre chose que l'interpolation (citer papier de neuro bio.). Pour revenir aux réseaux de neurones; un résultat clé est le théorème universel d'approximation qui permet d'approximer n'importe quelle fonction par un réseau de neurone. Dès lors nos structures actuelles deviennent légitimes pour tenter de rapprocher l'apprentissage machine (créée à partir du conscient humain). Néanmoins de par la finitude dimensionelle de cette approche, il peut être trop ambitieux d'espérer atteindre ces capacités de généralisation et d'apprentissage humain car la machine pourrait toujours atteindre par cette approche des limites fondamentales: exemple parlant le cas 1 pound of steel vs 2 pounds of feathers, erreur qu'un humain ne ferait pas. Malgré tout bien que cette limite fondamentale puisse demeurer, elle pourrait néanmoins demeurer invisible avec les progrès incessants de l'IA. Mieux comprendre ce qu'est la généralisation au sens de la machine, être capable de la quantifier, d'identifier les mécanismes qui la favorisent sont l'objet de ce manuscrit. 
    \end{comment}




\chapter*{Preamble: Human Learning, Machine Learning and Generalisation}
\addcontentsline{toc}{chapter}{Preamble: Human Learning, Machine Learning and Generalisation}\mtcaddchapter


\addtextlist{lof}{Preamble}

This manuscript tackles the notion of \emph{generalisation} a notion built upon the general notion of \emph{learning}. For a brief moment, let's take the luxury of forgetting about machines and concentrate on learning at its most human. 

\paragraph{Apprehending human learning} A human being (here a learner) is structured around experiences, either lived or passed on by others. 

The learner then benefit from these experiences in various ways, for instance, by considering a mediated experience to be true (fire burns) and acting on this assumption, whereas reiteration or denial of this same information may be symptoms of zero truth value.  These scenarios can just as easily appear for a lived experience (the question of hallucinations). This first dichotomy in information processing is intrinsically linked to a clearly stated question: does fire burn? Can I trust my senses or have I hallucinated? In these cases, learning has taken place by subjecting the experience to its truth value in relation to a simple question (in this case with two outcomes).  This vision can easily be extended to a multiple (and finite) tree of possibilities. Indeed, we can extend the burning question as follows: what is the intensity of the burn as a function of the temperature of the fire? We can then establish a multitude of answers representing various degrees of burn. 

However, many questions cannot be reduced to a finite number of possibilities. For example, what is fire? To answer this question, it is nevertheless possible to exploit multiple facets of experience (wood fire, twig, rock) to propose that fire is the chemical reaction of oxygen in the air with a combustible material, with a supply of energy serving as the trigger. 

Then, a legitimate question is: why has mankind understood the nature of fire? This fundamental understanding emerged from practical considerations: how can we stop being cold? Can we eat meat other than raw to reduce the risk of illness? It then takes multiple interactions with the environment to generate experiences and then learn from them to gradually respond to a complex need (how to make a fire to keep yourself warm?).

Thus, through this preliminary analysis, we have found several premises of understanding human learning.

\begin{itemize}
    \item How is learning formalised structurally?
    The learner must base the experience on simple questions to acquire primary certainties. These latter acquired, it is possible to reach complex questions by interweaving more and more elementary considerations.
    \item Where does the need to learn come from?
    From a practical point of view, the emergence of these complex questions often arises from a relationship between the being and its environment, making it possible to develop contextual objectives. The learner then gradually becomes capable of responding to complex needs through a succession of simple actions.
\end{itemize}
 
\paragraph{From human to machine learning} 

Machine learning has been structured around two approaches, the first symbolic, which takes advantage of human extrapolations to teach the machine to manipulate an axiomatic, and the second, statistical, which consists of providing the machine with a large number of experiments so that it learns from multiple empirical examples. We are going to focus on the second approach because it underpins a large part of modern research.
This method requires a large number of experiments to be transmitted to the machine, which then extracts the knowledge through optimising procedures. More precisely, the knowledge extracted depends on the question posed and its mathematical translation. We can see parallels with human learning described above: you need experiments and a question to reduce reality to something learnable. To go a step further, the variety of human learning scenarios described above can be applied to modern machine learning: the question "Does fire burn?" can be associated with supervised learning, which learns from multiple-choice questions. The question "What is fire?" can be associated with unsupervised learning, which, in the case of clustering, looks for similarities between numerous experiments that are not induced by the question. Finally, the question "Can I make a fire?" can be linked to reinforcement learning which focuses on the progress of an agent learning from its interaction with the environement.

\paragraph{From learning to generalisation.}

Generalisation can be seen as the ability to exploit learning from experience beyond that experience. This encompasses a theoretical and axiomatic understanding of a phenomenon, i.e. a fruitful extrapolation, or the ability to exploit the knowledge acquired for a new, never-before-seen situation, i.e. to interpolate experiences. 

This dual aspect of generalisation can be found in both humans and machines in a variety of ways. Deep neural networks, which are the spearhead of modern machine learning, are based on finite-dimensional learning spaces, which means that a problem can be learned through a finite number of founding principles. Since the number of principles can be increased as far as numerical capacity allows, we can say that neural networks have discrete generalising power. Given that machine learning methods are correlated with their human counterparts, we might then ask whether the power of human generalisation (and even learning) is also discrete. It seems cavalier to assert this, because even if it is possible to suppose that the conscious part of the human mind reasons on a finite horizon and has a countable power (transmitted, moreover, to the machine, which learns according to human methods), this dimension obscures the quantity of information constantly captured and filtered by our brain, as well as its unconscious assimilation, In other words, the fact that our brain is as much a part of abstract thought as it is of biological thought can potentially generate a generalisation power that relates to a wider infinity and thus provide a continuous generalisation power (relating more to the line than to the point). So how can we think about generalisation in humans when, mathematically, our simplest intuitions fail us when this continuous power is involved (the ball of radius 1 is not compact in infinite dimension, \citealp{riesz1955lecons})? We might also ask whether extrapolation exists in such structures or whether it all boils down to interpolation \citep{hasson2020direct}.

\paragraph{What to expect from generalisation in modern machine learning?}

So what can we expect from artificial neural networks and their ability to generalise to humans? Universal approximation theorems (see \eg \citealp{lu2017expressive,park2021minimum}) ensure that neural networks are capable of approximating any function living in a space to the power of the continuum (\eg the space of continuous functions with compact support which does not admit a countable base as a Banach space), making these structures promising candidates for partially understanding human generalisation mechanisms.
In the near future, machine approximations will potentially be powerful enough to give the illusion of human generalisation capacity. Nevertheless, it is worth bearing in mind that, if the thesis of a fundamental inequality in nature between the powers of human and machine generalisation is confirmed, then artificial neural networks will never fully attain the world-understanding capacities of their two-generation counterparts. It is stll worth noticing artificial neural nets ability to approximate this human intelligence makes these structures valuable assistants, enriching the capabilities of any individual. That being said, this manuscript aims to provide a better understanding of generalisation in machine learning, to be able to quantify it and to identify the mechanisms that promote it.







JURY: 


Rapporteurs: Alquier (sur)/Chopin (moins)

Membres: Seldin (rapporteur mais peut etre pas fou pour le rapport)/ Pascal Germain (rapporteur) Gérard (si Pierre pas dispo), John Shawe-Taylor (examinateur), Emilie Morvant (présidente) + le Maitre + Arnak Dalalyan (trop proche?), Alessandro Rudi
 


CHALLENGE HERE: being very rigorous on the lit review.
\newpage